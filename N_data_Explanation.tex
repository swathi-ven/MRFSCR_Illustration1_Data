
\documentclass{article}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{geometry}
\usepackage{graphicx}

\setcounter{MaxMatrixCols}{10}
%TCIDATA{OutputFilter=LATEX.DLL}
%TCIDATA{Version=5.00.0.2552}
%TCIDATA{<META NAME="SaveForMode" CONTENT="1">}
%TCIDATA{Created=Friday, March 04, 2016 08:48:02}
%TCIDATA{LastRevised=Sunday, April 21, 2024 13:01:46}
%TCIDATA{<META NAME="GraphicsSave" CONTENT="32">}
%TCIDATA{<META NAME="DocumentShell" CONTENT="Standard LaTeX\Blank - Standard LaTeX Article">}
%TCIDATA{Language=American English}
%TCIDATA{CSTFile=40 LaTeX article.cst}

\newtheorem{theorem}{Theorem}
\newtheorem{acknowledgement}[theorem]{Acknowledgement}
\newtheorem{algorithm}[theorem]{Algorithm}
\newtheorem{axiom}[theorem]{Axiom}
\newtheorem{case}[theorem]{Case}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{conclusion}[theorem]{Conclusion}
\newtheorem{condition}[theorem]{Condition}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{criterion}[theorem]{Criterion}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{exercise}[theorem]{Exercise}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{notation}[theorem]{Notation}
\newtheorem{problem}[theorem]{Problem}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{solution}[theorem]{Solution}
\newtheorem{summary}[theorem]{Summary}
\newenvironment{proof}[1][Proof]{\noindent\textbf{#1.} }{\ \rule{0.5em}{0.5em}}
\input{tcilatex}
\geometry{left=1in,right=1in,top=1in,bottom=1in}

\begin{document}

\noindent We consider a dataset that consists of $300$ observations on
terminal sample size 'N' obtained by employing (i) Purely Sequential
strategy (4.1) (ii) Accelerated Sequential strategy (4.12) with $k=2,3$ and $%
4$ and (iii) Three-stage strategy (4.19)-(4.21) with $\kappa =1/2$ and $1/3$
to construct $95\%$ MRFSCR for unknown $\mathbf{\mu }$. The calculation of
'N' was carried out by first generating random samples from $N(\mathbf{\mu }%
,\sigma ^{2}H)$ population with $\mathbf{\mu =}\left( 
\begin{array}{c}
3 \\ 
5 \\ 
2%
\end{array}%
\right) $, $\sigma ^{2}=16$ and $H=\left( 
\begin{array}{ccc}
5 & -4 & 1 \\ 
-4 & 6 & -4 \\ 
1 & -4 & 5%
\end{array}%
\right) $ and fixing $\alpha =0.05,$ $\rho =1.0$\ in the loss function (3.5),%
$C=1000$,$d=0.1768$,$\beta =0.5$ $m=15$ and $m_{0}=30$. Then, under this
fixed structure, we run the Purely Sequential stopping rule (4.1), the
Accelerated Sequential stopping rule (4.12) with $k=2,3$ and $4$ and the
Threee-stage stopping rule (4.19)-(4.21) with $\kappa =1/2$ and $1/3$
independently of each other $b=300$ times. These stopping times are labelled $N_{i};i=1,2,3,4,5,6$ respectively.

From the theory discussed in Sec 4.1 in (4.7), we can claim that $N_{1}\sim
N(C,gC)$ with $g=2p^{-1}(1-\beta )^{2}$ (In our case, $p=3$ and $\beta
=0.5\Rightarrow g=\frac{1}{6}$). From the theory discussed in Sec 4.2 in
(4.15), we can claim that $N_{i}\sim N(C,kgC)$ when $(i,k)$ corresponds to $%
(2,2),(3,3),(4,4)$ respectively. Also, from the theory discussed in Sec 4.3
in (4.23) part (iii), we can claim that $N_{i}\sim N(C,kgC)$ when $(i,k)$
corresponds to $(5,2),(6,3)$ respectively. Since $N_{i}^{\prime }s$ are
independent, we can claim $\mathbf{N}_{6\times 1}=$ $\left(
N_{1},N_{2},N_{3},N_{4},N_{5},N_{6}\right) ^{T}\sim N_{6}(\mathbf{\mu }%
,\Sigma =\sigma ^{2}H)$ where $\mathbf{\mu }=(C,C,C,C,C,C)^{T}$ and $\sigma
^{2}=C$, $H=g%
\begin{pmatrix}
1 & 0 & 0 & 0 & 0 & 0 \\ 
0 & 2 & 0 & 0 & 0 & 0 \\ 
0 & 0 & 3 & 0 & 0 & 0 \\ 
0 & 0 & 0 & 4 & 0 & 0 \\ 
0 & 0 & 0 & 0 & 2 & 0 \\ 
0 & 0 & 0 & 0 & 0 & 3%
\end{pmatrix}%
$.\\

This represents the distribution of our 'population'. A sample of size 300
from this population is considered as our real dataset.\\

The multivariate normality of the dataset was checked by means of the
Henze-Zirkler test (p-value $=0.3136$) implying
that the multivariate normality assumption worked reasonably well. One may
also employ other available tests of multivariate normality normality, such
as (Mardia Skewness p-value=$0.6164$; Mardia Kurtosis p-value=$0.7736$
, Royston's test (p-value=$0.9869$)\ \ and
many more. The univariate normality of each individual variable was also
verified with the Anderson-Darling test (p-values=$%
0.7087,0.8063,0.7920,0.7469,\\
0.5714,0.8516$).

\end{document}
